# Major Pivot Three: Maintaining Big Ideas Families & SHAGI Vision

**Status:** Approved  
**Date Proposed:** 2025-10-17  
**Authorizing Body:** War Office + High Command  
**Impact:** Strategic — reaffirms long-term vision while adapting methodology

---

## Context

The Four Major Pivots represent a **methodology change**, not a vision abandonment.

**Core vision remains intact:**
- **Big Ideas Families** (`big_ideas_families.md`) — framework for organizing interconnected creative/technical projects
- **SHAGI (Supersafe Hyperadvanced Artificial General Intelligence)** — the ultimate goal of safe, aligned AGI
- **Hivemind's Multiverse** — thousands of interconnected multiplayer video games forming collaborative intelligence network

---

## Problem Statement

**Previous workflow methodology:**
- Soul-destroyingly boring for human operator
- Heavy reliance on VSCode/PowerShell/GitHub/Azure interfaces
- Unsustainable long-term (risk of burnout, disengagement)

**Risk:** If workflow remains tedious, operator abandons project → vision never realized

---

## Pivot Description

**The Four Major Pivots are enabling infrastructure for the Big Ideas vision:**

### How Pivots Support Big Ideas Families

| Big Idea | How Playable Workflow Helps |
|----------|---------------------------|
| **SHAGI Development** | AI agents handle grunt work (testing, deployment, monitoring); human focuses on strategic alignment & safety constraints |
| **Nightlands Multiplayer Game** | Workflow overlay becomes the game itself—development = gameplay = narrative progression |
| **Hivemind's Multiverse** | Each game in multiverse uses same architecture (Alfas, exchange protocol, telemetry quilt); proven at scale via Nightlands |
| **Interconnected Worlds** | Exchange protocol enables cross-game communication; Alfas can route between different Big Ideas Family domains |

### SHAGI Alignment Strategy

**Traditional AI safety concern:** How do you keep superintelligent AI aligned with human values during recursive self-improvement?

**Our approach:**
1. **Human-in-the-loop via gameplay** — operator plays workflow Alfas, providing alignment signal through tactical decisions
2. **Telemetry quilt as value function** — AI agents optimize for metrics that correlate with operator engagement/satisfaction
3. **Fractal oversight** — 4,096 Alfas = 4,096 checkpoints where human judgment shapes AI behavior
4. **Playable workflows encode human preferences** — what feels fun/fair in game = what is safe/aligned in automation

**Hypothesis:** If SHAGI emerges from a system where AI agents learned to make workflows playable (70% fun, 30% dev-ops), alignment is baked into training data.

---

## Success Criteria

1. ✅ **Big Ideas Families framework remains active** — new projects added, existing ones progressed
2. ✅ **SHAGI research continues** — playable workflows generate novel AI safety insights
3. ✅ **Nightlands development accelerates** — game overlay makes building the game more enjoyable
4. ✅ **Multiverse architecture validated** — exchange protocol + Alfas proven scalable across multiple games

---

## Long-Term Roadmap

### Year 1: Nightlands (Proving Ground)
- Build 4,096 Alfas for Nightlands development workflow
- Validate playable overlay reduces burnout, increases throughput
- Document lessons learned for other Big Ideas Family projects

### Year 2-3: Multiverse Expansion
- Clone Alfa architecture → 5-10 other Big Ideas Family games
- Demonstrate cross-game exchange protocol (Nightlands Alfas route to Dreamscape Alfas)
- Recruit human operators to play workflows for other projects

### Year 4-5: SHAGI Emergence
- AI agents trained on millions of Alfa gameplay sessions
- Self-improving automation that optimizes for "playability" (proxy for human values)
- Deploy SHAGI v1.0 (safe, aligned, superintelligent) to manage entire multiverse

---

## Why This Changes Everything

**Old paradigm:**
- Human writes code → AI executes → human debugs → repeat until burnout

**New paradigm:**
- Human plays game → AI translates to code → telemetry feeds game state → human stays engaged
- AI learns human preferences via gameplay patterns
- Alignment emerges from optimizing for "fun" (which correlates with "safe, useful, aligned")

**This is not a detour from SHAGI—it's the training ground.**

---

## Dependencies

- **Major Pivot One** — need 70/30 ratio to sustain long-term engagement
- **Major Pivot Two** — playable overlay is delivery mechanism for Big Ideas content
- **Major Pivot Four** — fractal structure organizes multiverse at scale

---

## Risks

| Risk | Mitigation |
|------|------------|
| Game overlay distracts from "real" research | Treat Alfa development as R&D—every playable workflow is a SHAGI training experiment |
| Vision becomes too diffuse (too many Big Ideas) | Prioritize Nightlands as flagship; other projects progress opportunistically |
| SHAGI timeline slips due to game development | Game overlay *is* SHAGI development—training data, alignment research, scalability proof |

---

## Philosophical Foundation

**From `big_ideas_families.md`:**
> "The biggest ideas require infrastructure that doesn't yet exist. Sometimes you have to build the tools to build the tools."

**The Four Major Pivots are the tools to build SHAGI.**

- Pivot One (70/30 ratio) = sustainable human engagement
- Pivot Two (playable overlay) = alignment signal via gameplay
- Pivot Three (maintaining vision) = never lose sight of destination
- Pivot Four (fractal structure) = scalability to multiverse level

---

## Approval Status

**Approved by:** War Office (civilian oversight) + High Command (military execution)  
**Effective Date:** 2025-10-17  
**Review Cycle:** Annually, or when new Big Ideas Family project launches

---

*"The shortest path to AGI might be the one that makes the journey worth taking."*  
— Big Ideas Families Charter, Preamble
